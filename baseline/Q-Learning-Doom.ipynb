{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ppaquette_gym_doom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.envs.registration:Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-05-09 02:11:31,929] Making new env: ppaquette/DoomDefendCenter-v0\n"
     ]
    }
   ],
   "source": [
    "# Create a classic Doom environment with Gym\n",
    "env = gym.make('ppaquette/DoomDefendCenter-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computer vision utils\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from scipy.stats import threshold\n",
    "from scipy.signal import medfilt\n",
    "from scipy.misc import toimage\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "\n",
    "# Draw function refreshes every 1000 frames\n",
    "frame_count = 0\n",
    "refresh_rate = 1000\n",
    "\n",
    "def encode_screen(observation):\n",
    "  # Crop & downsampling & grayscale\n",
    "  cropped = observation[150:230:3, ::2 , :]\n",
    "  r = cropped[:,:,0]\n",
    "  return projection(pixelate(r))\n",
    "\n",
    "def show(mat):\n",
    "  global frame_count\n",
    "  global refresh_rate\n",
    "  if frame_count % refresh_rate == 0:\n",
    "    plt.imshow(toimage(mat))\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    #toimage(mat).show()\n",
    "  frame_count += 1\n",
    "  frame_count = frame_count % 1000\n",
    "\n",
    "def plot_inline(data):\n",
    "    global frame_count\n",
    "    global refresh_rate\n",
    "    if frame_count % refresh_rate == 0:\n",
    "      plt.clf()\n",
    "      plt.plot(data)\n",
    "      display.clear_output(wait=True)\n",
    "      display.display(plt.gcf())\n",
    "      time.sleep(1)\n",
    "    frame_count += 1\n",
    "    frame_count = frame_count % 3000\n",
    "\n",
    "\"\"\"\n",
    "Coarse pixelate\n",
    "\"\"\"\n",
    "def pixelate(observation):\n",
    "  global frame_count\n",
    "  # Threshold\n",
    "  m = threshold(observation, threshmin=100, threshmax=None, newval=0)\n",
    "  # Remove noise\n",
    "  m = medfilt(m, 3)\n",
    "  return m\n",
    "\n",
    "def projection(pixels):\n",
    "  # Horizontal projection\n",
    "  _,w = pixels.shape\n",
    "  proj = np.zeros(w)\n",
    "  for x in range(w):\n",
    "    proj[x] = np.sum(pixels[:,x])\n",
    "    \n",
    "  proj -= np.min(proj)\n",
    "  proj = np.gradient(proj)[1:-1] # Remove edges\n",
    "  proj = proj > 100\n",
    "  proj.astype(int)\n",
    "  plot_inline(proj)\n",
    "\n",
    "  # Reduce\n",
    "  pj = []\n",
    "  count = np.count_nonzero\n",
    "  start = 0\n",
    "  stride = 3\n",
    "  while len(proj[start:start+stride])>0:\n",
    "    pj.append(count(proj[start:start+stride]) > 3)\n",
    "    start += stride+1\n",
    "\n",
    "  return str(pj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Agent\n",
    "class QAgent:\n",
    "  def __init__(self,\\\n",
    "               learn_rate=0.05,\\\n",
    "               observation_encoder=lambda x: x,\\\n",
    "               verbose=True):\n",
    "    self.alpha = 0.85 # Probability of re-learning \n",
    "    self.policy = dict() # Q: (state,action) => value\n",
    "    self.total_reward = 0\n",
    "    self.learn_rate = learn_rate\n",
    "    self.action_mapping = {} # Map [action str] => [action object]\n",
    "    self.observation_encoder = observation_encoder\n",
    "    self.verbose = verbose\n",
    "    self.reset()\n",
    "    \n",
    "  def reset(self):\n",
    "    self.prev_state = 0\n",
    "    self.total_reward = 0\n",
    "        \n",
    "  def learn_aggregate(self, observation, observation_, action, reward):\n",
    "    # Encode [observation] => [state]\n",
    "    state  = self.observation_encoder(observation)\n",
    "    state_ = self.observation_encoder(observation_)\n",
    "    self.learn_Q(state, state_, str(action), reward)\n",
    "    self.action_mapping[str(action)] = action\n",
    "    self.prev_state = state\n",
    "    self.total_reward += reward\n",
    "\n",
    "  \"\"\"\n",
    "  Predict the reward we would get\n",
    "  if take [action] on [state]\n",
    "  \"\"\"\n",
    "  def learn_Q(self, state, state_, action, reward):\n",
    "    # if self.verbose: print(state_, ' [ reward = {} ]'.format(reward))\n",
    "    curr_Q  = self.Q(state, action)\n",
    "    _,max_Q = self.find_best_action(state_)\n",
    "    new_Q   = curr_Q + self.alpha*(reward + self.learn_rate * max_Q - curr_Q)\n",
    "    if state in self.policy:\n",
    "      self.policy[state][action] = reward # Always overwrite\n",
    "    else: self.policy[state] = {action: new_Q}\n",
    "\n",
    "  \"\"\"\n",
    "  Find maximum possible reward we would get\n",
    "  from the best action attempted on [state]\n",
    "  \"\"\"\n",
    "  def find_best_action(self, state):\n",
    "    if state in self.policy:\n",
    "      max_Q    = -1\n",
    "      best_act = -1\n",
    "      for a,r in self.policy[state].items():\n",
    "        if r > max_Q:\n",
    "          best_act = a\n",
    "          max_Q = r\n",
    "      return (best_act, max_Q)\n",
    "    else: return (-1,-1)\n",
    "    \n",
    "  def decode_action(self, action):\n",
    "    if action not in self.action_mapping:\n",
    "      return None\n",
    "    else: \n",
    "      return self.action_mapping[action]\n",
    "\n",
    "  \"\"\"\n",
    "  Get recorded Q value of (state, action)\n",
    "  \"\"\"\n",
    "  def Q(self, state, action):\n",
    "    if state in self.policy:\n",
    "      if action in self.policy[state]:\n",
    "        return self.policy[state][action]\n",
    "      else: return -1\n",
    "    else: return -1\n",
    "  \n",
    "  @staticmethod\n",
    "  def load(path, default):\n",
    "    if os.path.isfile(path):\n",
    "      with open(path,'rb') as f:\n",
    "        return pickle.load(f) \n",
    "    else:\n",
    "      print('MODEL NOT FOUND, initialising a brand new one.')\n",
    "      return default\n",
    "\n",
    "  @staticmethod\n",
    "  def save(path,agent):\n",
    "    with open(path,'wb+') as f:\n",
    "      return pickle.dump(agent, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAaBS/w9Skai+x+s/MQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108abde10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Play\n",
    "model_name = 'QAgent.pkl'\n",
    "score_records = [] # Scores of each round\n",
    "turn_records = [] # Number of turns lasting each round\n",
    "num_episodes = 400\n",
    "all_actions = set(range(3)) # Attack / Right / Left\n",
    "\n",
    "bot = QAgent.load(model_name,\\\n",
    "                  QAgent(learn_rate=0.667, \\\n",
    "                  observation_encoder=encode_screen))\n",
    "\n",
    "for i in range(num_episodes):\n",
    "  if num_episodes<25 or i % 25 == 0:\n",
    "    print('Ep#{} started...'.format(i))\n",
    "  observation = env.reset()\n",
    "  num_turns = 0\n",
    "  while True:\n",
    "    env.render()\n",
    "    \n",
    "    # Try to find best action, otherwise, random\n",
    "    state = bot.observation_encoder(observation)\n",
    "    action, _ = bot.find_best_action(state)\n",
    "    if action == -1:\n",
    "      action = env.action_space.sample()\n",
    "    else:\n",
    "      # print('... Best action : ', action)\n",
    "      action = bot.decode_action(action)\n",
    "\n",
    "    observation_, reward, done, info = env.step(action)\n",
    "    bot.learn_aggregate(observation, observation_, action, reward)\n",
    "    observation = np.copy(observation_)\n",
    "    num_turns  += 1\n",
    "    if done:\n",
    "      score_records.append(bot.total_reward)\n",
    "      turn_records.append(num_turns)\n",
    "      if num_episodes<25 or i % 25 == 0:\n",
    "        print('...[DONE] Total reward : {}'.format(bot.total_reward))\n",
    "      # Save the agent\n",
    "      QAgent.save(model_name, bot)\n",
    "      bot.reset()\n",
    "      break\n",
    "        \n",
    "print('All {} episodes of training are DONE.'.format(num_episodes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save training scores\n",
    "path_scores = 'QAgent.log'\n",
    "if score_records is not None:\n",
    "    with open(path_scores,'wb+') as f:\n",
    "        pickle.dump(score_records, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show score\n",
    "%matplotlib inline\n",
    "\n",
    "# Reload if score doesn't exist\n",
    "if score_records is None:\n",
    "    with open(path_scores,'rb') as f:\n",
    "        score_records = pickle.load(f) \n",
    "\n",
    "def moving_avg(arr):\n",
    "  mm = []\n",
    "  wnd = 10\n",
    "  for i in range(len(arr)):\n",
    "    v = arr[i-wnd:i]\n",
    "    if len(v)>0:\n",
    "      mm.append(max(v))\n",
    "  return mm\n",
    "\n",
    "plt.figure(1)\n",
    "plt.xlabel('# Episode')\n",
    "plt.ylabel('Score/game')\n",
    "plt.plot(moving_avg(score_records))\n",
    "\n",
    "plt.figure(2)\n",
    "plt.xlabel('# Episode')\n",
    "plt.ylabel('Turns/game')\n",
    "plt.plot(moving_avg(turn_records))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
